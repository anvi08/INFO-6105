{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div style=\"text-align: right\">INFO 6105 Data Sci Engineering Methods and Tools, Week 4 Lecture 2</div>\n",
    "<div style=\"text-align: right\">Dino Konstantopoulos, 29 September 2022, with material from Cam Davidson-Pilon</div>\n",
    "\n",
    "* * * \n",
    "*At the end of this lecture, you should a good understanding of probability distributions, how to estimate probabilities for different outcomes and sample spaces, how to use Bayes' theorem to answer typical interview questions involving probabilities, and start thinking about finding a job in high-stakes sports!*\n",
    "\n",
    "*For next week, reading homework: Chapter 6 of your textbook, Mathematics for Machine Learning*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework solution\n",
    "\n",
    " Determine the probability that the sum of a three-dice roll is prime:\n",
    " \n",
    "<center>\n",
    "<img src=\"ipynb.images/3-dice-roll.png\" width=\"200\" />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fractions import Fraction\n",
    "def p(event, space): \n",
    "    \"\"\"The probability of an event, given a sample space of equiprobable outcomes.\n",
    "    event can be either a set of outcomes, or a predicate (true for outcomes in the event).\"\"\"\n",
    "    if is_predicate(event):\n",
    "        event = such_that(event, space)\n",
    "    return Fraction(len(event & space), len(space))\n",
    "\n",
    "is_predicate = callable\n",
    "\n",
    "def such_that(predicate, collection): \n",
    "    \"\"\"The subset of elements in the collection for which the predicate is true.\"\"\"\n",
    "    return {e for e in collection if predicate(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = {1,2,3,4,5,6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "D3 = {(d1, d2, d3) for d1 in D for d2 in D for d3 in D}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 1, 1),\n",
       " (1, 1, 2),\n",
       " (1, 1, 3),\n",
       " (1, 1, 4),\n",
       " (1, 1, 5),\n",
       " (1, 1, 6),\n",
       " (1, 2, 1),\n",
       " (1, 2, 2),\n",
       " (1, 2, 3),\n",
       " (1, 2, 4),\n",
       " (1, 2, 5),\n",
       " (1, 2, 6),\n",
       " (1, 3, 1),\n",
       " (1, 3, 2),\n",
       " (1, 3, 3),\n",
       " (1, 3, 4),\n",
       " (1, 3, 5),\n",
       " (1, 3, 6),\n",
       " (1, 4, 1),\n",
       " (1, 4, 2),\n",
       " (1, 4, 3),\n",
       " (1, 4, 4),\n",
       " (1, 4, 5),\n",
       " (1, 4, 6),\n",
       " (1, 5, 1),\n",
       " (1, 5, 2),\n",
       " (1, 5, 3),\n",
       " (1, 5, 4),\n",
       " (1, 5, 5),\n",
       " (1, 5, 6),\n",
       " (1, 6, 1),\n",
       " (1, 6, 2),\n",
       " (1, 6, 3),\n",
       " (1, 6, 4),\n",
       " (1, 6, 5),\n",
       " (1, 6, 6),\n",
       " (2, 1, 1),\n",
       " (2, 1, 2),\n",
       " (2, 1, 3),\n",
       " (2, 1, 4),\n",
       " (2, 1, 5),\n",
       " (2, 1, 6),\n",
       " (2, 2, 1),\n",
       " (2, 2, 2),\n",
       " (2, 2, 3),\n",
       " (2, 2, 4),\n",
       " (2, 2, 5),\n",
       " (2, 2, 6),\n",
       " (2, 3, 1),\n",
       " (2, 3, 2),\n",
       " (2, 3, 3),\n",
       " (2, 3, 4),\n",
       " (2, 3, 5),\n",
       " (2, 3, 6),\n",
       " (2, 4, 1),\n",
       " (2, 4, 2),\n",
       " (2, 4, 3),\n",
       " (2, 4, 4),\n",
       " (2, 4, 5),\n",
       " (2, 4, 6),\n",
       " (2, 5, 1),\n",
       " (2, 5, 2),\n",
       " (2, 5, 3),\n",
       " (2, 5, 4),\n",
       " (2, 5, 5),\n",
       " (2, 5, 6),\n",
       " (2, 6, 1),\n",
       " (2, 6, 2),\n",
       " (2, 6, 3),\n",
       " (2, 6, 4),\n",
       " (2, 6, 5),\n",
       " (2, 6, 6),\n",
       " (3, 1, 1),\n",
       " (3, 1, 2),\n",
       " (3, 1, 3),\n",
       " (3, 1, 4),\n",
       " (3, 1, 5),\n",
       " (3, 1, 6),\n",
       " (3, 2, 1),\n",
       " (3, 2, 2),\n",
       " (3, 2, 3),\n",
       " (3, 2, 4),\n",
       " (3, 2, 5),\n",
       " (3, 2, 6),\n",
       " (3, 3, 1),\n",
       " (3, 3, 2),\n",
       " (3, 3, 3),\n",
       " (3, 3, 4),\n",
       " (3, 3, 5),\n",
       " (3, 3, 6),\n",
       " (3, 4, 1),\n",
       " (3, 4, 2),\n",
       " (3, 4, 3),\n",
       " (3, 4, 4),\n",
       " (3, 4, 5),\n",
       " (3, 4, 6),\n",
       " (3, 5, 1),\n",
       " (3, 5, 2),\n",
       " (3, 5, 3),\n",
       " (3, 5, 4),\n",
       " (3, 5, 5),\n",
       " (3, 5, 6),\n",
       " (3, 6, 1),\n",
       " (3, 6, 2),\n",
       " (3, 6, 3),\n",
       " (3, 6, 4),\n",
       " (3, 6, 5),\n",
       " (3, 6, 6),\n",
       " (4, 1, 1),\n",
       " (4, 1, 2),\n",
       " (4, 1, 3),\n",
       " (4, 1, 4),\n",
       " (4, 1, 5),\n",
       " (4, 1, 6),\n",
       " (4, 2, 1),\n",
       " (4, 2, 2),\n",
       " (4, 2, 3),\n",
       " (4, 2, 4),\n",
       " (4, 2, 5),\n",
       " (4, 2, 6),\n",
       " (4, 3, 1),\n",
       " (4, 3, 2),\n",
       " (4, 3, 3),\n",
       " (4, 3, 4),\n",
       " (4, 3, 5),\n",
       " (4, 3, 6),\n",
       " (4, 4, 1),\n",
       " (4, 4, 2),\n",
       " (4, 4, 3),\n",
       " (4, 4, 4),\n",
       " (4, 4, 5),\n",
       " (4, 4, 6),\n",
       " (4, 5, 1),\n",
       " (4, 5, 2),\n",
       " (4, 5, 3),\n",
       " (4, 5, 4),\n",
       " (4, 5, 5),\n",
       " (4, 5, 6),\n",
       " (4, 6, 1),\n",
       " (4, 6, 2),\n",
       " (4, 6, 3),\n",
       " (4, 6, 4),\n",
       " (4, 6, 5),\n",
       " (4, 6, 6),\n",
       " (5, 1, 1),\n",
       " (5, 1, 2),\n",
       " (5, 1, 3),\n",
       " (5, 1, 4),\n",
       " (5, 1, 5),\n",
       " (5, 1, 6),\n",
       " (5, 2, 1),\n",
       " (5, 2, 2),\n",
       " (5, 2, 3),\n",
       " (5, 2, 4),\n",
       " (5, 2, 5),\n",
       " (5, 2, 6),\n",
       " (5, 3, 1),\n",
       " (5, 3, 2),\n",
       " (5, 3, 3),\n",
       " (5, 3, 4),\n",
       " (5, 3, 5),\n",
       " (5, 3, 6),\n",
       " (5, 4, 1),\n",
       " (5, 4, 2),\n",
       " (5, 4, 3),\n",
       " (5, 4, 4),\n",
       " (5, 4, 5),\n",
       " (5, 4, 6),\n",
       " (5, 5, 1),\n",
       " (5, 5, 2),\n",
       " (5, 5, 3),\n",
       " (5, 5, 4),\n",
       " (5, 5, 5),\n",
       " (5, 5, 6),\n",
       " (5, 6, 1),\n",
       " (5, 6, 2),\n",
       " (5, 6, 3),\n",
       " (5, 6, 4),\n",
       " (5, 6, 5),\n",
       " (5, 6, 6),\n",
       " (6, 1, 1),\n",
       " (6, 1, 2),\n",
       " (6, 1, 3),\n",
       " (6, 1, 4),\n",
       " (6, 1, 5),\n",
       " (6, 1, 6),\n",
       " (6, 2, 1),\n",
       " (6, 2, 2),\n",
       " (6, 2, 3),\n",
       " (6, 2, 4),\n",
       " (6, 2, 5),\n",
       " (6, 2, 6),\n",
       " (6, 3, 1),\n",
       " (6, 3, 2),\n",
       " (6, 3, 3),\n",
       " (6, 3, 4),\n",
       " (6, 3, 5),\n",
       " (6, 3, 6),\n",
       " (6, 4, 1),\n",
       " (6, 4, 2),\n",
       " (6, 4, 3),\n",
       " (6, 4, 4),\n",
       " (6, 4, 5),\n",
       " (6, 4, 6),\n",
       " (6, 5, 1),\n",
       " (6, 5, 2),\n",
       " (6, 5, 3),\n",
       " (6, 5, 4),\n",
       " (6, 5, 5),\n",
       " (6, 5, 6),\n",
       " (6, 6, 1),\n",
       " (6, 6, 2),\n",
       " (6, 6, 3),\n",
       " (6, 6, 4),\n",
       " (6, 6, 5),\n",
       " (6, 6, 6)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prime_sum(outcome): return is_prime(sum(outcome))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dua Lipa prime code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_prime(n): return ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fraction(1, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p(prime_sum, D3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Introduction to Probability Distributions\n",
    "\n",
    "Your textbook, in page 6, states that the foundations of Machine Learning are:\n",
    "\n",
    "<center>\n",
    "<img src=\"ipynb.images/foundations-of-ML.png\" width=\"500\" />\n",
    "</center>\n",
    "\n",
    "\n",
    "## The Binomial distribution\n",
    "And so let's start with a little lab that introduces a very important probability distribution: The [binomial](https://en.wikipedia.org/wiki/Binomial_distribution). We will get to know other important distributions in class throughout the semester (and of course you already know about that beautiful distribution: The Gaussian or *normal* distribution). The binomial looks a bit like the Gaussian, but if you look closely, the \"*bell*\" has a different shape.\n",
    "\n",
    "<br />\n",
    "<center>\n",
    "<img src=\"http://statistics.wdfiles.com/local--files/ch6/binomial.png\" width=\"400\" />\n",
    "Binomial\n",
    "</center>\n",
    "\n",
    ">**Definition**: The binomial distribution with parameters $n$ and $p$ is the discrete probability distribution of the number of successes in a sequence of $n$ *independent* experiments, each asking a yes–no question, and each with its own boolean-valued outcome: success/yes/true/one (with probability $p$) or failure/no/false/zero (with probability $q = 1 − p$).\n",
    "\n",
    "> If the random variable X follows the binomial distribution with parameters n ∈ ℕ and p ∈ [0,1], we write X ~ B(n, p). The probability of getting exactly k successes in n independent Bernoulli trials is given by the **probability mass function**: $$f(k) = {n \\choose k} p^{k} (1-p)^{n-k}$$\n",
    "\n",
    ">where $\\binom {n}{k}$ is our famous ***choose*** function from previous lecture: $${n \\choose k} = \\frac{n!}{k!(n-k)!}$$\n",
    "\n",
    ">The formula can be understood as follows: $k$ successes occur with probability $p^k$ and $n − k$ failures occur with probability $(1 − p)^{n − k}$. However, the $k$ successes can occur *anywhere* among the $n$ trials, and there are $\\binom {n}{k}$ different ways of distributing $k$ successes in a sequence of $n$ trials, just like there are $\\binom {23}{6}$ different ways of selecting 6 balls from an urn of 23.\n",
    "\n",
    ">**Example**: Suppose a **biased** coin comes up heads with probability 0.3 when tossed. The probability of seeing exactly 4 heads in 6 tosses is:\n",
    "\n",
    ">$$f(4, 6, 0.3) = {6 \\choose 4} 0.3^{4} (1 - 0.3)^{6 - 4} = 0.06$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's plot a few binomial distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUIAAADrCAYAAAAcyZ8OAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAArVElEQVR4nO3deZxU5Z3v8c+vqveFpZtm64VmlaCypVkUFVyQBkxITGI0k3WSoJNgMpp4b/KaJHfuTDKTO9fxJnfUICaaRKMYvaggCAqKiUFkUdlFGhrotoGGZuu9u6qe+8epgqKp7j61dW2/t69+ddepc049h5Yvz3POs4gxBqWUSmWOWBdAKaViTYNQKZXyNAiVUilPg1AplfI0CJVSKU+DUCmV8tJiXYBABg0aZMrLy2NdDKVUktm+ffspY0xR1+1xGYTl5eVs27Yt1sVQSiUZETkSaLs2jZVSKU+DUCmV8jQIlVIpT4NQKZXyNAiVUilPg1AplfJSJghdbg9PbT7CuZbOWBdFKRVnUiYIn99ey09f2s26vcdjXRSlVJxJiSBs63Tzq/UfAXCqqT3GpVFKxZuUCMI/bDrMifPtiMDppo5YF0cpFWeSPgjPtXby6MaDzB5XRPGAbBqaNQiVUpdK+iB8/C+HONfayQPzrqAwN0ODUCl1maQOwvrGNn73djWfmjScq4r7U5iXyelmvUeolLpUUgfhw29U0en28IO54wAoyM2gQe8RKqW6SNogPNrQwjPvHuWL00opH5QLQGGe1TTWJUyVUv6SNggfen0/aU7hezePvbCtMDeDDpeHpnZXDEumlIo3SRmEVfWNvLyjjm/MGsmQflkXthfkZgJwWh+YKKX8JGUQ7qk7jzFw+5TiS7YX5mUAcErvEyql/CRlEPqavv2z0y/ZXphrBaHWCJVS/pIzCNusIMzNvHRJlsI8q2ncoMPslFJ+kjMI212IQE6G85LtvhqhdqpWSvlL2iDMy0xDRC7ZnpXuJDfDqX0JlVKXSM4gbLOCMJCCvAwdXaKUukRyBmF790FYmJupTWOl1CWSNwizugtCHWanlLpU8gZhdzXCvAztPqOUuoStIBSRShHZLyJVIvKjAO//nYjs9H5tEpFJfu8dFpFdIvKBiGyLZOG70+M9wtxMGprbdbyxUuqCwGnhR0ScwCPAXKAW2CoiK40xe/12qwZmG2POiMh8YBkww+/9G40xpyJY7h71VCMclJdBp9vQ2O6iX1Z6wH2UUqnFTo1wOlBljDlkjOkAlgOL/HcwxmwyxpzxvtwMlES2mMHp6R5hga8vod4nVEp52QnCYqDG73Wtd1t3vgm86vfaAK+JyHYRWRx8EYNjjOmxRlhwYZiddqFRSll6bRoDEmBbwBtsInIjVhBe57d5ljGmTkQGA6+LyIfGmL8EOHYxsBigrKzMRrECa+lwYww9NI2tYXY68YJSysdOjbAWKPV7XQLUdd1JRCYCvwUWGWMafNuNMXXe7/XAi1hN7csYY5YZYyqMMRVFRUX2r6AL34QLvTWN9cmxUsrHThBuBcaKyEgRyQDuBFb67yAiZcAK4CvGmI/8tueKSL7vZ+BWYHekCh/IhSDstWmsQaiUsvTaNDbGuERkCbAOcAJPGGP2iMg93veXAj8DCoFHveN7XcaYCmAI8KJ3WxrwjDFmbVSuxMs380x3QZiV7iQvM00XeldKXWDnHiHGmDXAmi7blvr9/C3gWwGOOwRM6ro9mnqrEYJ2qlZKXSrpRpb0do8QdDU7pdSlki8IvU3j/MzuO0vrxAtKKX/JF4Ttvtmpnd3uY028oPcIlVKWpA3CnprGvnuEOt5YKQVJGoQZTgeZad3XCAtyM3B5DOdbdX1jpVQyBmGbq8dmMVwcXdKgw+yUUiRjEPYw4YJPgS7ipJTyk5xB2MMTY9AZaJRSl0q+IGxzkd9DZ2q42DTWTtVKKUjGIGzv/R7hwFyrxqhdaJRSkKRBmNfLzNOZaU7ys9L0HqFSCkjWIOylaQzeTtUahEopkjEI21zk9dI0BijMy9RZqpVSQJIFocvtobXT3etTY9CJF5RSFyVVEDZ3uIGeh9f5DMrTprFSypJUQegbZ9xb9xmwaoSnmzvweHS8sVKpLrmCsM0384ydhyWZuD2G822d0S6WUirOJVcQtluhZqdpXJinw+yUUpYkC0LvPUKbNULQYXZKqWQLQt/s1DZqhLrQu1LKJ7mC0Ns0tnWP0Ns01oXelVJJFYSNvSzl6W9gjq5vrJSyJFUQNgdxjzAjzUG/rDSdeEEplVxB2NTeSXa6E6dDbO0/KE9Xs1NK2QxCEakUkf0iUiUiPwrw/t+JyE7v1yYRmWT32EiyMzu1Px1mp5QCG0EoIk7gEWA+MAG4S0QmdNmtGphtjJkI/CuwLIhjI6ap3W1rVImPbzU7pVRqs1MjnA5UGWMOGWM6gOXAIv8djDGbjDFnvC83AyV2j42kprbOIGuE2jRWStkLwmKgxu91rXdbd74JvBrisWFpaneRm2E/CAflZXCmRccbK5Xq7ARhoCcPAZNDRG7ECsL/HsKxi0Vkm4hsO3nypI1iXa6xLfh7hG6P4VyrjjdWKpXZCcJaoNTvdQlQ13UnEZkI/BZYZIxpCOZYAGPMMmNMhTGmoqioyE7ZL9Pc0fvCTf4KdX1jpRT2gnArMFZERopIBnAnsNJ/BxEpA1YAXzHGfBTMsZFkLe4eRBDqsp5KKaDX1DDGuERkCbAOcAJPGGP2iMg93veXAj8DCoFHRQTA5a3dBTw2StcSUvcZ0BlolEp1tlLDGLMGWNNl21K/n78FfMvusdHQ7nLT6Ta2RpX46FRcSilIopElwcw84+Mbb6zD7JRKbckThN5p+oPpPpPudNA/O50zWiNUKqUlTRBemHkmiBoh6PrGSqkkCsLmIBZu8jcw1+pUrZRKXUkThL6mcbA1woE5GZxu1g7VSqWypAvCYPoRgtU01un6lUptSReEITWNmzsxRscbK5WqkicIQ3xYUpCbTofbQ3OHOxrFUkolgOQJwnYXDoHsdGdQxxV4l/U8rcPslEpZSROEjd5xxt4hfrYV5KYDcFqfHCuVspImCJvbg5t5xsc3ukQ7VSuVupImCIOdcMGnMNc3FZcGoVKpKqmCMNiuMwADvU1jrREqlbqSKgiDmXnGJy8zjXSn6D1CpVJY8gRhmyuomWd8RISC3Ax9aqxUCkueIAxy4SZ/A3MytEaoVApLniAMcuEmfwW5GXqPUKkUlhRBaIyhKciFm/wV5OpC70qlsqQIwpYON8YEP7zOpyBXm8ZKpbKkCMJQZ57xGZiTwbnWTlxuTySLpZRKEEkRhBdmpw6jaWwMnNWF3pVKSUkRhBdmpw6jaQzaqVqpVJUUQXhhdurM9JCO9wWhPjBRKjXZqkKJSCXwa6xF2n9rjPlll/fHA08CU4F/MsY86PfeYaARcONd+D0yRb/I1zTOzQxuCi4f38QLCRWE1X+FF/4ePF2a82lZ8KU/w7CJsSmXUgmo1yAUESfwCDAXqAW2ishKY8xev91OA98DPtPNaW40xpwKs6zdurhwU2g1Qt9C7wn15Hjr41YIXv2FS7e/9xRs/z3c9lBMiqVUIrJTI5wOVBljDgGIyHJgEXAhCI0x9UC9iCyMSil7EerCTT4DchJs4oXWs7B/LVT8Pcz/5aXvtZyGPSug8peQlhGT4imVaOzcIywGavxe13q32WWA10Rku4gsDqZwdl3sPhNa0zgzzUleZlrirGa392Vwt8PEOy5/b+IXofUMVK3v+3IplaDsBGGgKZ+DWeloljFmKjAf+K6I3BDwQ0QWi8g2Edl28uTJIE5v3SPMcDrITAstCME3uiRBVrPb+WcoHAvDp1z+3ugbIWcQ7Hyu78ulVIKyE4S1QKnf6xKgzu4HGGPqvN/rgRexmtqB9ltmjKkwxlQUFRXZPT1g3SMMtVnsMzA3g9MtCVAjPFsDR962an6BliVwpsNVn4P9r1pNaKVUr+wE4VZgrIiMFJEM4E5gpZ2Ti0iuiOT7fgZuBXaHWtjuhDoXob+CnPTEuEe463nr+9Wf736fiV+0ms77bP2alEp5vQahMcYFLAHWAfuAPxtj9ojIPSJyD4CIDBWRWuB+4CciUisi/YAhwNsisgPYAqw2xqyN9EX4Fm4KR0FuZvx3nzHGavKWzoSCkd3vVzwVCkZbTWilVK9spYcxZg2wpsu2pX4/H8dqMnd1HpgUTgHtCHXhJn8FuenxH4THd8HJD2FhL11jRGDSnfDmL6ym9IDSnvdXKsUlzciSSNwjbO100xrPC73vfA4c6XDlZ3vf19e/cPcL0S2TUkkgaYIw3KZxYW6cd6r2uK37g2NvhZyC3vcvGAmlM2DHc1aTWinVraQIwsa28B+WxP36xtVvQdOJwH0HuzPxDji5D05E/PmUUkklKYKwuT20hZv8xf3ECzv/DJn9YVyl/WOuvB0cadqnUKleJHwQutweWjvd4dcI4zkIO5ph3yq4chGkZ9k/LqfAakrvesFqWiulAkr4IGxut/6CR+weYTwG4f5XoaPJ6h8YrIl3QOMxqP5L5MulVJJI+CBs6vDNPBNeEPbLSschcCYeH5Z8tA5yB0PZtcEfO24+pGXDgdciXy6lkkTiB2FbeDPP+DgcwsCcDBrisUZYuwXKZoAjhF9XepY1JrlmS+TLpVSSSPwgbLfGB4fbNIY4Xd+48QScOWx1hQlV6XQ4tgM62yJWLKWSScIHYbgLN/kbGI/rG9d6a3LhBqGnE459EJEiKZVsEj4IfQ9Lwu0+A1CQE4dBWLMFnBkwLIyRiiXeCX9q3o1MmWxq7GjkP7b+B68feb1PP1epYCV8EPqaxpGoERbkZcTfw5KaLTBsMqRlhn6OvCIoGNWn9wn3Nuzli698kaf2PsX9G+/n55t/Trs7QeZ7VCkn4YPw4sJNkakRnmnpxOOJkyFprg6oe99q2oarZLoVhFEebmeMYfmHy/nymi/T4e7giXlP8I0rv8Fz+5/jy2u+zNHzR6P6+UqFIuGD8OJSnpG5R+j2GM63xckErcd3WvMKRiIIS6dDc7314CVKGjsa+cFbP+AX7/6CmcNm8sKnXmDa0GncX3E/D9/0MMeaj3HHK3ewtjriM7EpFZaED8Lbp5Tw5Nen4XQEWlEgOHHXqdp3T68kQkEIULs1/HMFcK79HHe+cidvHH2D+z95Pw/f/DADsgZceH926Wyev+15xgwYwwN/eYDHdjwWlXIoFYqED8KywhxuHD84IufyDbOLm/uENVugfxn0Gxb+uQZPgIy8qD0weXrf0xxtPMpjcx/jG1d9A4dc/r/WsLxhPFn5JHNHzGXZzmWcbAlubRqloiXhgzCSCrwz0DQ0xVEQRqJZDOBwQvEno/LApLGjkT/t/RM3l93MjGE9d/NJd6Rz39T7cBs3T+55MuJlUSoUGoR+CvLiqEZ4rhYa6yIXhGD1RTyxG9qbIndO4Jl9z9DY2cjiifZWay3tV8qCkQt4fv/zNLQ2RLQsSoVCg9CPr0YYF+sb+5qwEQ3C6WA88PH2iJ2yubOZp/Y9xeyS2UwonGD7uG9P/Dbt7nb+sPcPESuLUqHSIPSTneEkK90RH+sb12yB9BwYclXkzllSYX2vjVzz+Ln9z3Gu/Rx3T7w7qONG9h9JZXklyz9cztm2sxErj1Kh0CDsojA3M05qhFtg+FRrneJIyR4IReMjdp+w1dXKH/b8gWuHX8vVRVcHffy3J36bVlcrT+17KiLlUSpUGoRdDMxNj/09ws5Wqw9hJJvFPiXTrC40Hk/Yp3p+//OcbjsddG3QZ+zAsdxSdgvP7HuG8x3nwy6PUqHSIOwiLqbiqnsfPK7oBGHpDGg9Aw1VYZ2m3d3O7/f8nulDpzN1yNSQz3P3pLtp6mzimX3PhFUepcKhQdhFXEzFFcmO1F1d6FgdXvN4xYEVnGw9GXJt0Gd8wXjmlMzhqb1P0dQR2afZStllKwhFpFJE9otIlYj8KMD740XkHRFpF5EfBnNsvImPINwChWMgtzDy5y4cC1kDwupY3eHu4He7fseUwVOYNnRa2EW6e9LdnO84z/L9y8M+l1Kh6DUIRcQJPALMByYAd4lI134Sp4HvAQ+GcGxcKcjJoLHdRbsrRosdGWMFYTRqg2DNcl0yDWpCH2q37vA6TrScYPHExYiEP7TxqkFXMWv4LJ7e+zQujyvs8ykVLDs1wulAlTHmkDGmA1gOLPLfwRhTb4zZCnR93NrrsfHGN8zubEuMnhyfPgQtp6Jzf9CndIa13nHr2ZAOX31oNcNzh3Pt8BDWUOnG58d9noa2Bt491rdzJioF9oKwGKjxe13r3WZHOMfGRMwnXvBNihDVIPQ2Z2u3BX3oqdZTvHPsHRaMWhBwPHGori+5nvz0fFYfWh2xcypll53/kwO1fexOamf7WBFZLCLbRGTbyZOxG4wf8/WNa96FzH5Wf79oKf4kiCOkBybrDq/DYzwsHLkwokXKdGYyt3wuG45uoNXVGtFzK9UbO0FYC5T6vS4B6mye3/axxphlxpgKY0xFUVGRzdNHXkHMg3CrFVQOZ/Q+IzMfBl8Z0gOT1YdWc8XAKxgzcEzEi7Vw5EJaXC1srNkY8XMr1RM7QbgVGCsiI0UkA7gTWGnz/OEcGxMFsZyKq70J6vdYDzOiraQCPn4vqI7VR84fYdepXSwcFdnaoE/F0AoG5wzW5rHqc70GoTHGBSwB1gH7gD8bY/aIyD0icg+AiAwVkVrgfuAnIlIrIv26OzZaFxMJA7KtIW0xmYrr2AfWpAh9EoTToP08NBywfcia6jUIwvyR86NSJIc4WDByAX/7+G+caTsTlc9QKhBbd7uNMWuMMeOMMaONMb/wbltqjFnq/fm4MabEGNPPGDPA+/P57o6NZ2lOB/2zYzTMzvegxDc5QjT5wtbmjNXGGNYcWkPF0AqG5g6NWrEWjlqIy7h05TvVp3RkSQCFsVrfuHYbFIyGnILof1bhGMjqbzsI9zbs5fD5wxF/SNLVFQOvYHT/0do8Vn1KgzCAQfmZnDjf1rcfaowVSn3RLAarY3Vxhe0uNK8ceoV0Rzpzy+dGtVgiwsJRC3mv/j3qmuw+k1MqPBqEAZQV5HCkoaVvP/RcDTSd6JtmsU9JBdTv7XXGarfHzdrDa7mh5Ab6ZfSLerEWjFoAWPckleoLGoQBlBfmUN/YTmtHHw6z89XM+jQIp1kPZ+re73G3d4+/y6nWU1F7WtxVcV4xUwZPYfWh1Zgor8OsFGgQBlRWmAvA0dN9WCus3QZpWZGdkbo3xZ/0fnbP9wlXH1pNfno+N5Tc0AeFsiwcuZCqs1V8dOajPvtMlbo0CAMYUZADwOGG5r770NqtMHxKZGek7k1OgfXQpIf7hG2uNjYc3cAtI24h05nZZ0W7tfxW0iRNH5qoPqFBGMCIQisIj/bVfUJXOxzb0bfNYh/fjNXdNEE31m6kubO5z5rFPgOzBjKreBarq1fjMeHPpq1UTzQIAxiQk0H/7HSOnO6jGuHx3eBut57i9rXiT0JzPZw9GvDttdVrKcouomJI35dtwcgF1LfU8359z/cwlQqXBmE3RhT24ZPjCx2p+6jrjL8eOlY3dTTx19q/cmv5rTijOfa5G3NK55DlzGJt9do+/2yVWjQIu9GnXWg+3gb5w6F/DGYoG3IlpGUHXOv4zZo36fB0UFle2fflAnLSc7i+5HpeP/I6bk+MJspVKUGDsBsjCnP4+Gwrne4+uD9VuzU29wfBejgzfErAGuFrh19jSM4QJhZNjEHBLPPK59HQ1sD2E5FblF6prjQIuzGiMBe3x1B3Nspz4zWdhDOHY9Ms9impsB7WuC4ubH++4zxv173NvPJ5EZ2ANVg3lNxAdlo2aw9r81hFjwZhN3xdaKLePP7Y15E6lkE4DdwdcHzXhU1vHn0Tl8fFvPJ5sSsXkJ2WzeyS2aw/sl7XM1FRo0HYjRHeTtVHot2XsHYriBOGTYru5/TE1yz3ax6vPbyW4rxirh50dYwKdVFleSVn2s+w5Xh4S5Aq1R0Nwm4Mzs8kM80R/Rph7TYYehVk5ET3c3rSbzj0K77Qsfps21k2123m1vJbI7JKXbiuK7mOnLQc1h1eF+uiqCSlQdgNh0OsLjTRHGbncVuzRMeyWexTUnGhRvhGzRu4TOybxT6ZzkxuLLuR9UfW0+mJ0eqCKqlpEPagrCA3uqNLTu6HjsY4CcJpcPYINNWztnotpfmlTCiInyWoK8srOd9xns11m2NdFJWENAh7YNUIm6M3A0osO1J35S3D6eqNbDm+hcryyrhoFvtcO/xa8tPz9emxigoNwh6MKMyhrdNDfWN77zuHonYrZA+EglHROX8whk0CRxrrD63Gbdxx0yz2yXBmcGPZjbx59E063DFaYVAlLQ3CHlx8chyl5nHtNmt8cTzUvNKzYchVrDuzh/J+5YwbOC7WJbpMZXkljZ2NbKrbFOuiqCSjQdiDi30Jo9CFpvEEnNwHI66J/LlDdKpkKttoY17pTXHVLPaZOWwm/TL66dNjFXEahD0oHpiN0yHRqREefMP6PvrmyJ87RK/n98cjQmX6oFgXJaB0Zzq3jLiFN2vepN0dpdsVKiVpEPYg3elg+ICs6HShObgBcgbB0NiN4+1qdeNHjOlwMebY3lgXpVuV5ZU0dzbzZs2bsS6KSiK2glBEKkVkv4hUiciPArwvIvJ/ve/vFJGpfu8dFpFdIvKBiNhbMi2OlBfmcjTSTWOPx6oRjr7JWk0uDhw8e5Adp3bxmcwhULUh1sXp1vSh0xmaO5SXDrwU66KoJNLr30IRcQKPAPOBCcBdItK1g9l8YKz3azHwmy7v32iMmWyMidEUK6ErK4hCp+rjO6ClAcbcEtnzhmHFgRWkSRq3lS+EU/vhXG2sixSQ0+HkM2M+w6a6Tbrcp4oYO9WR6UCVMeaQMaYDWA4s6rLPIuCPxrIZGCAiwyJc1pgYUZjD2ZZOzrVEcESDr8Y1+qbInTMMne5OVh1cxZzSORSOv83aGMe1ws+M+QwAL1e9HNuCqKRhJwiLgRq/17XebXb3McBrIrJdRBaHWtBYKSvwdqGJ5LT9B9+w7g3mFUXunGHYWLuRM+1n+OzYz0LReGuS2Kr1sS5Wt4rzipkxbAYvVb2k65moiLAThIH6UXQdatHTPrOMMVOxms/fFZGAa0KKyGIR2SYi206ePGmjWH2jfFCEp+NqOw8178KY+HlavOLACgbnDGbW8FlWn8YxN8Ght8Adv9Ne3T72duqa69h8TIfcqfDZCcJaoNTvdQnQ9eZMt/sYY3zf64EXsZralzHGLDPGVBhjKoqK4qOmBNY9QojgGsfVfwGPK266zRxvPs6muk0sGr3o4rokY26B9nMBp++PFzeV3UT/zP68eODFWBdFJQE7QbgVGCsiI0UkA7gTWNlln5XAV71Pj2cC54wxx0QkV0TyAUQkF7gV2B3B8kddTkYaRfmZketUfXADZORB6YzInC9ML1e9jMd4rGaxz6g5IA6rrHEq05nJbaNuY8PRDZxtOxvr4qgE12sQGmNcwBJgHbAP+LMxZo+I3CMi93h3WwMcAqqAx4HveLcPAd4WkR3AFmC1MSbhRs2PKMjhcCSaxsZYDyHKr4e0jPDPFyaP8fBi1YtMHzqd0ny/Cn32QGuZzzh+YALw2TGfpdPTyepqXQRehSfNzk7GmDVYYee/banfzwb4boDjDgExnHo5MsoKc9hU1RD+iU4fsqa6uvbe8M8VAVuPb+Xjpo9ZMmXJ5W+Ovhne+l/QchpyCvq+cDZcUXAFVxZeyYoDK/jS+C/F5bBAlRjiozdvnCsvzOX4+TbaOsNcUtJXw4qTByUrDqwgPz2fW8oC9GccczNg4FB8j+C4feztfHTmI/Y2xO9oGBX/NAhtGFFoPTCpCfeBycENMHBkXEy7da79HOuPrGfBqAVkpWVdvsPwqZA1AKre6POyBWP+yPlkObNYcWBFrIuiEpgGoQ2+J8dh3Sd0dUD1X+OmNrimeg0dng5uH3t74B2cadZDk4MbrHubcSo/I5+5I+aypnoNra4oL72qkpYGoQ0RWdGuZjN0NsdFtxmP8fD8R88zvmA8Ewp7mI5/zM3QeAzq9/Vd4ULw2bGfpamziVerX411UVSC0iC0YWBOOvlZaeH1JaxaD440GHl95AoWovVH1nPgzAG+OuGrPe/oC+047kYDUDGkggmFE1i2c5ku7qRCokFog4h3RbtwmsZVb0DpTMjMj1zBQuD2uHn0g0cZ1X8UC0Yu6Hnn/sXWkLs4Hm4H1u9nyeQlfNz0MS9VvRTr4qgEpEFo04jCXA6ebArt4NPVcGJXXNwffPXwqxw8d5DvTP7OxZEkPRlzCxzZBM0R6D4URdcVX8ekokk8tuMxnbRVBU2D0KaZIwuoPdPKh8fPB3/wu49ZzeJJd0a+YEHo9HTymw9+wxUDr2DuiLn2Dpr8d+DugO1PRLdwYRIR7p1yLydaTvDCRy/EujgqwWgQ2jT/6mE4HcKqHUHOgdd2Dt5/Cq76HPQbHp3C2bTq4CqONh5lyZQlOMTmr37IBGu6sC2Pgyu+a1ozhs1g+tDpPL7zcX2CrIKiQWjToLxMrh1dyKodx4Jb5/i9P0JHE8z8Tu/7RlGHu4OlO5Zy9aCrmV0yO7iDr/kuNJ2A3fHfV2/JlCU0tDWw/MPlsS6KSiAahEH49KThHD3dwo7ac/YOcLtg81JrbPHwyVEtW29WHFjBseZjLJm8JPihaKNvth6avPNIXPcpBJgyeAqzimfxxO4naOoI8Z6uSjkahEG49cqhZDgdrPzAZvN438twvtaqUcVQm6uNZTuXMXXwVK4ZHsLyoSLWNZzYZU0jFufunXwvZ9vP8vS+p2NdFJUgNAiD0D87nTlXFPHKzjrcnl5qRsbApoehYDSMndc3BezGc/uf42TrSe6dcm/oExNcfYe16t47j0S2cFFw5aAruan0Jv6454+ca7dZe1cpTYMwSJ+aNJz6xna2VJ/uecead6HuPbjmOzFdqe5U6yl+t+t3zBw2k4qhYaydlZ4F078NB9bBqQORK2CUfGfyd2jsbOQ3O7quI6bU5TQIg3TzJwaTk+Fk1c5emsfvPGxNWjDprj4pVyCdnk5++NYPaXW18sC0B8I/YcU3wZkJmx8N/1xRdkXBFdw1/i7+tO9PrDu8LtbFUXFOgzBIORlp3PKJIby66xid7m4WDjp9CPa9AhV/Dxm5fVtAP7/a/iu2n9jOz675GeMGjgv/hHlFMPEO+ODZuO9gDfBAxQNMLJrIT//2Uw6dPRTr4qg4pkEYgk9NGs6Zlk7erjoVeAdfB+rpsVu0b231Wv6494/cNf4uPjX6U5E78TXfBVdr3HewBkh3pvPQ7IfITsvm+29+X58iq25pEIbghnGD6JeVFrhzdctpeM/XgTo2SztXnaniZ5t+xuSiyTxQEYEmsb/Bn7C602x5HDrjv9PykNwhPDj7QWoaa/jp334aXB9QlTI0CEOQmeak8qqhvLbnxKWzVrs64Pmvg7s9ZtPxN3Y0ct/G+8hJy+E/5/wn6c70yH/IdfdZHaxf+gfwxP+6wtOGTuO+T97H+qPreXLPk7EujopDGoQh+vSkYpraXWzcX29tMAZW3gvVb8Gn/wuGXtXnZXJ73Pzk7Z9Q01jDg7MfZHDO4Oh80Mjr4dafw54X4fWfRuczIuyrE77KvPJ5/Pq9X/NO3TuxLo6KMxqEIZo5qoBBeRms9DWP3/g57FwON/4TTP5Sn5fnZMtJ7l5/N2/UvMH9n7w/vK4ydlyzBKbfbT0d37y09/1jTET4l2v/hZH9RrJkwxKe/fBZbSarCzQIQ5TmdLDw6mGs31fP4XUPw18fhKlfhRsifE/Ohr99/Dc+v+rz7KjfwT9f8898ZcJXov+hIlD57zD+Nlj7I9jbdanr+JOTnsMTlU8wfdh0/u3df+O+jfdph2sFaBCG5e7Zo/lc3h5KNv2U+iHXw8L/YwVEH+n0dPLQ9oe4Z/09FGQVsPy25Xxu3Of6bllLhxM+91somQYrvg1H3+2bzw1DQVYBj9z8CD+s+CFv1b7FF1Z9gQ/qP4h1sVSMaRCGyu1i+NFX+Df3f3IkfRRzjnyDpW8f6ZPmlsd42Hp8K19f+3We3P0kXxj3BZ5d+CyjB4yO+mdfJj0b7loO/Yrh2S/Ch6vj/gGKQxx87cqv8dT8p3CKk6+v/ToPv/8wJ1tOxrpoKkbEzl9cEakEfg04gd8aY37Z5X3xvr8AaAG+box5z86xgVRUVJht27YFeSl9pKMF3n8a3vkvOHsUBl9J210v8MDaE6zaUceXZpTxL5++kjRn5P+NqW2sZdXBVbx88GU+bvqY/Ix8/sc1/4N55bEdywxYncifuh3OVMOgK2DW96zxyWkZsS5Zjxo7GvnXzf/Kq9Wv4hQn1w6/lkVjFjGndA6ZzsxYF09FmIhsN8ZcdgO91yAUESfwETAXqAW2AncZY/b67bMAuBcrCGcAvzbGzLBzbCBxF4SuDusv+J6XYMtj0NIApTNg1j/CuEpwOPB4DA++tp9HNx7k+rGD+MrMEUwsGcCQfpkhNVXdHje1TbVUna3i0NlDvHPsHbYe34ogzBg2g0VjFnFz2c1kp2VH/HJD5nbB3pfgb7+C47sgf5g1D+P4hTBghLVEaJyqPlfNqoOrWHlwJSdaTtAvox9zR8xlQuEERg8YzZgBY+if2T/WxVRhCicIrwH+2Rgzz/v6xwDGmH/32+cxYKMx5lnv6/3AHKC8t2MDCSYIjx//gPqG/Ze/Eei6jAG8X8bj/TLWVPSuNivwXG1WP8DmU3CuFs7VwPljgAcDUHoNTPwiDLvKe8pLP2f93uM8/nY1LrcH8NA/N51Rg3IoH5RNXpbgdBicTg8Ohxunw0OHp5VWVyMt7iZaXY00u5poaD/BsZYjdHo6Lpx3WE4Zs4bMY9bQWynMGmLrzyZmjCG/7q8M2bmU/GObrE2SRnu/Mtr6j6K9/2g6s4vwpGXjScvGOLOsn50Z3nusDow4QByAYC78O+L/D0p07oO6jYfdzR/x5tktbG/cTavn4qzcA9L6UZI5hH7OPHKd2eQ5c8hxWN8zHOmkiROnOEkTJ2mShgPBIQ7kwn94/1GUAFfTd/eWk8WQgWVMv/qWoI7pLgjt/BNdDNT4va7FqvX1tk+xzWPD8uLm/82j53ZG8pSXygPy/Prjuavh/V/C+90fklEKvgZhJ7Af2N/L0FzjzsB4sjHubIyrH572Gbjbh+BpH4KnYzCNnkw+Ap7kIHAwnCvqI2nAEsbJIq6WakY56hh1+hijznxIubxFpsTvspsTgDuw/sk87nRSlZHOwfR0DmY0UZ1+kjqHg/NOB+cdDlx9+HBMXWrmh/lBB2F37ARhoN901+pWd/vYOdY6gchiYDFAWVmZjWJZFk79B646/l4370qAH8WqdXhrGyDgzLDuZTkzIS0T0tIhLSfgE+BAzVy58C+8XLKfQxwX1gbpdBtcLgcejwO3x4HL5cTldpDuyCLbkYtIGgaDx1xey4Ru/tASwrRLXtUBdR43TlcLTncrDlcrTncbTlcr4ulAMGAM4q2xi+/KL/kz6ds/jX7AFO+XP2MM7aaTZk8bLuPChRuXsb7cuPEYg+8/D+aS36vB/+dAEvc33leGFUTu4aCdIKwFSv1el2D9/2xnnwwbxwJgjFkGLAOraWyjXACUlV1HWdl1dndXSqnL2Hm0uRUYKyIjRSQDuBPo2nt2JfBVscwEzhljjtk8VimlYqrXGqExxiUiS4B1WF1gnjDG7BGRe7zvLwXWYD0xrsLqPvONno6NypUopVSIbPUj7Gtx131GKZUUuntqrCNLlFIpT4NQKZXyNAiVUilPg1AplfLi8mGJiJwEjgRxyCCgm5WUEpJeT3xLputJpmuB3q9nhDGmqOvGuAzCYInItkBPghKVXk98S6brSaZrgdCvR5vGSqmUp0GolEp5yRKEy2JdgAjT64lvyXQ9yXQtEOL1JMU9QqWUCkey1AiVUipkCR+EIlIpIvtFpEpEfhTr8gRLRJ4QkXoR2e23rUBEXheRA97vA2NZRrtEpFRE3hSRfSKyR0S+792eqNeTJSJbRGSH93r+p3d7Ql4PWEtviMj7IvKK93XCXguAiBwWkV0i8oGIbPNuC/qaEjoIvWuiPALMx5pY+C4RmRDbUgXt90Bll20/AjYYY8YCG7yvE4EL+IEx5hPATOC73t9Hol5PO3CTMWYSMBmo9E4zl6jXA/B9YJ/f60S+Fp8bjTGT/brNBH9NxpiE/QKuAdb5vf4x8ONYlyuE6ygHdvu93g8M8/48DNgf6zKGeF0vYy3clfDXA+QA72EtNZGQ14M1MfIG4CbgFe+2hLwWv2s6DAzqsi3oa0roGiHdr5WS6IYYa2JbvN8H97J/3BGRcqzZ7d8lga/H25T8AKgHXjfGJPL1/Ar4b4D/wtOJei0+BnhNRLZ7l/uAEK4pftdXtMf2miiq74hIHvD/gH80xpwPZTnTeGGMcQOTRWQA8KKIXBXjIoVERG4D6o0x20VkToyLE0mzjDF1IjIYeF1EPgzlJIleI7SznkoiOiEiwwC83+tjXB7bRCQdKwT/ZIxZ4d2csNfjY4w5C2zEup+biNczC/i0iBwGlgM3icjTJOa1XGCMqfN+rwdeBKYTwjUlehAm65ooK4GveX/+Gta9trgnVtXvd8A+Y8xDfm8l6vUUeWuCiEg2cAvwIQl4PcaYHxtjSowx5Vh/T94wxnyZBLwWHxHJFZF838/ArcBuQrmmWN/sjMDN0gXAR1iL/f5TrMsTQvmfBY5hLYFcC3wTKMS6qX3A+70g1uW0eS3XYd2a2Al84P1akMDXMxFrBeud3r9gP/NuT8jr8buuOVx8WJKw1wKMAnZ4v/b4/v6Hck06skQplfISvWmslFJh0yBUSqU8DUKlVMrTIFRKpTwNQqVUytMgVEqlPA1CpVTK0yBUSqW8/w/MDEJEFIVUagAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 360x270 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# n and p are exactly as defined above\n",
    "import numpy as np\n",
    "from scipy.stats import binom\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "n_values = [20, 25, 40]\n",
    "p_values = [0.1, 0.5, 0.5]\n",
    "x = np.arange(0, 50)    \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 3.75))\n",
    "\n",
    "for (n, p) in zip(n_values, p_values):\n",
    "    # create a binomial distribution\n",
    "    dist = binom(n, p)\n",
    "\n",
    "    plt.plot(x, dist.pmf(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate some **random variates** and plot their **histogram** to verify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16 16 17 17 15 13 18 15 18 19 14 18 10 15 16 13 18 14 17 15 17 17 17 20\n",
      " 16 17 15 18 13 18 16 15 15 18 15 17 15 18 17 16 14 17 15 15 16 14 15 19\n",
      " 18 16 15 16 16 15 13 16 15 15 15 15 16 17 16 15 17 18 17 17 16 15 18 18\n",
      " 16 13 17 15 16 18 13 16 18 18 15 17 16 18 14 12 14 17 16 17 17 15 18 17\n",
      " 16 17 19 17]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 0, 'Binomial'), Text(0, 0.5, 'Frequency')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sb, numpy as np\n",
    "from scipy.stats import binom\n",
    "#data_binom =binom.rvs(size=10,n=20,p=0.8)\n",
    "data_binom = binom.rvs(n=20,p=0.8,loc=0,size=100)\n",
    "print(data_binom)\n",
    "ax = sb.distplot(data_binom,kde=True,color='blue',hist_kws={\"linewidth\": 25,'alpha':1})\n",
    "ax.set(xlabel='Binomial', ylabel='Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approximations\n",
    "\n",
    "If you think the binomial *looks* like a bell curve, it does!\n",
    "\n",
    "If $n$ is large enough and the skew $p$ of the distribution is not too great (not too close to 0 or too close to 1), then a reasonable approximation to B(n, p) is given by a **normal distribution**!. In fact, it can be proven that it is close to:\n",
    "\n",
    "$$N(np, np(1-p))$$\n",
    "\n",
    "if both values $np$ and $n(1-p)$ are greater than or equal to 5. This approximation, known as de Moivre–Laplace theorem, is a huge time-saver when undertaking calculations by hand (exact calculations with large n are very onerous). Historically, it was the first use of the normal distribution, introduced in Abraham de Moivre's book *The Doctrine of Chances* in 1738.\n",
    "\n",
    "The binomial distribution also converges towards another distribution that we have not seen yet: the [Poisson distribution](https://en.wikipedia.org/wiki/Poisson_distribution), as the number of trials goes to infinity while the product $np$ remains fixed or at least $p$ tends to zero. Therefore, the Poisson distribution with parameter $λ = np$ can be used as an approximation to B(n, p) if $n$ is sufficiently large and $p$ is sufficiently small. According to two rules of thumb, this approximation is good if $n ≥ 20$ and $p ≤ 0.05$, or if $n ≥ 100$ and $np ≤ 10$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science with Danish Children\n",
    "So far, we have made the assumption that every outcome in a sample space (urn) is equally likely. In real life, we often get outcomes that are not equiprobable. For example, the probability of a child being a girl is not exactly 1/2, and the probability is slightly different for a second child. \n",
    "\n",
    "An [article](http://people.kzoo.edu/barth/math105/moreboys.pdf) (good Data Science article, you should read it) gives the following *counts* for two-child families in Denmark, where `GB` means a family where the first child is a girl and the second a boy:\n",
    "\n",
    "    GG: 121801    GB: 126840\n",
    "    BG: 127123    BB: 135138\n",
    "    \n",
    "How to work our `p` function with such distributions? We'll answer this question in this notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A bit of Python-fu\n",
    "\n",
    "Now, let's digress a bit into abstract computer science..\n",
    "\n",
    "In Python, `*args` and `**kwargs` is a common idiom to allow ***arbitrary number of arguments*** to functions. `*args` will give you all function parameters as a tuple, `**kwargs` will give you all keyword arguments (except those corresponding to a formal parameter) as a dictionary:\n",
    "```python\n",
    "def foo(*args):\n",
    "    for a in args:\n",
    "    print a\n",
    "        \n",
    "def bar(**kwargs):\n",
    "    for a in kwargs:\n",
    "        print a, kwargs[a]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s say we want to create a higher-order function that takes as input some function $f$ and returns a new function that for any input returns *twice* the value of $f$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_doubler(f):\n",
    "    def my_g(x):\n",
    "        return 2 * f(x)\n",
    "    return my_g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works.. in most cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "def f_plus_1(x):\n",
    "    return x + 1;\n",
    "\n",
    "h = my_doubler(f_plus_1)\n",
    "print(h(3)) #(3+1) * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "my_g() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m+\u001b[39m y;\n\u001b[0;32m      4\u001b[0m h \u001b[38;5;241m=\u001b[39m my_doubler(my_sum2)\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mh\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mTypeError\u001b[0m: my_g() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "def my_sum2(x, y):\n",
    "    return x + y;\n",
    "\n",
    "h = my_doubler(my_sum2)\n",
    "print(h(1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh *nooooo*!\n",
    "\n",
    "What we need is a way to specify a function that takes *arbitrary arguments*. This is where Python's `*args` and `**kwargs` come into play:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unnamed args:  (1, 2, 3, 4)\n",
      "keyword args:  {'key1': 'NU', 'key2': 'rocks!', 'key3': 'really!'}\n"
     ]
    }
   ],
   "source": [
    "def magic(*args, **kwargs):\n",
    "    print (\"unnamed args: \", args)\n",
    "    print (\"keyword args: \", kwargs)\n",
    "magic(1, 2, 3, 4, key1 = 'NU', key2 = 'rocks!', key3 = 'really!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "<center>\n",
    "    <img src=\"ipynb.images/magic.png\" width=300 />**Ohhhhhhhhhhhh**</a><br>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "args is a `tuple` of its unnamed arguments and kwargs is a `dictionary` of its named arguments. So now we can:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_new_doubler(f):\n",
    "    \"\"\"works no matter the inputs\"\"\"\n",
    "    def my_g(*args, **kwargs):\n",
    "        return 2 * f(*args, **kwargs)\n",
    "    return my_g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "h = my_new_doubler(my_sum2)\n",
    "print(h(1, 2))  # 6:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, ***now*** are ready to define **Probability distributions** in python, our new ***p*** function, where each outcome on the x-axis has its own distinct probability of being picked: One (high) value for rock star, one (low) value for Dino for the outcome of marrying Dua Lipa.\n",
    "\n",
    ">**Guess**: What python data structure are we likely to use to define probability distributions?\n",
    "\n",
    "We define `ProbDist` to take the same kinds of arguments that a `dict` does: either a **mapping** (from item to its probability) or a **set** of (key, val) pairs, and/or optional keyword arguments (because each ball in the urn is *special* now: it has its *own* probability of being picked). \n",
    "\n",
    ">**A dose of reality**: It's like all boys/girls are not equal! You will not just pick any boy/girl to be your girl/boyfriend! There are some that have a *much higher chance* of being picked by you (related to *your* taste)!\n",
    "\n",
    "This is the first time (in class), that we will define a Python `class`, instead of a Python **function/lambda**. That is why we will define its **constructor** `__init__()`. We assume `self` (`this` in Python) is composed of a set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "class ProbDist(dict):\n",
    "    \"\"\"A Probability Distribution; an {outcome: probability} mapping.\"\"\"\n",
    "    def __init__(self, mapping=(), **kwargs):\n",
    "        self.update(mapping, **kwargs)\n",
    "        # Make probabilities sum to 1.0; assert no negative probabilities\n",
    "        total = sum(self.values())\n",
    "        for outcome in self:\n",
    "            self[outcome] = self[outcome] / total\n",
    "            assert self[outcome] >= 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "We also need to modify the functions `p` and `such_that` to accept either a sample space as we had previously, or a probability distribution as the second argument `space`. \n",
    "\n",
    ">**Oh-oh**: Now we need to branch out on the ***2nd argument*** of function `p`!\n",
    "\n",
    "If we have a probability distribution, instead of *counting* each possible outcome equiprobably and thus just summing up `1`s (numerator: sum of all *favorable* outcomes, denominator: sum of all *possible* outcomes), we need to sum up the different discrete probabilities of each possible outcome: `sum(space[o] for o in space if o in event)`. \n",
    "\n",
    "We also need to modify `such_that()`, which is the set of all outcomes of our sample space for which the predicate (first) argument is `True`, so that its second argument can also be a `ProbDist`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3409497076.py, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [28]\u001b[1;36m\u001b[0m\n\u001b[1;33m    return sum({space[]})\u001b[0m\n\u001b[1;37m                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def p(event, space): \n",
    "    \"\"\"The probability of an event, given a sample space of equiprobable outcomes. \n",
    "    event: a collection of outcomes, or a predicate that is true of outcomes in the event. \n",
    "    space: a set of outcomes or a probability distribution of {outcome: frequency} pairs.\"\"\"\n",
    "    # branch on the type of the first argument\n",
    "    if is_predicate(event):\n",
    "        # transform the mapping (untangible) 'event' into the collection (tangible) 'event'\n",
    "        event = such_that(event, space)\n",
    "        \n",
    "    if isinstance(space, ProbDist):\n",
    "        # if space is a dictionary of distinct probabilities, where each item does not count as the same amount\n",
    "        return sum({space[]})\n",
    "    else:\n",
    "        # space is not a dictionary but a collection, let's fall back to our original division\n",
    "        return Fraction(len(event & space), len(space))\n",
    "\n",
    "is_predicate = callable\n",
    "\n",
    "def such_that(predicate, space): \n",
    "    \"\"\"The outcomes in the sample pace for which the predicate is true.\n",
    "    If space is a set, return a subset {outcome,...} with outcomes where predicate(element) is true;\n",
    "    if space is a ProbDist, return a ProbDist {outcome: frequency,...} with outcomes where predicate(element) is true.\"\"\"\n",
    "    if isinstance(space, ProbDist):\n",
    "        return ProbDist((o:v for o,v in space.items() if predicate(o)))\n",
    "    else:\n",
    "        return {o for o in space if predicate(o)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "And now we can finally take on the Danes from the data science paper!\n",
    "<br />\n",
    "<center>\n",
    "    <img src=\"ipynb.images/Danes.png\" width=300 />\n",
    "</center>\n",
    "\n",
    "# Danish two-child families: An introduction to *conditional* and *marginal* probabilities\n",
    "Here is the probability distribution for Danish two-child families as a `dictionary`, describing the probability of each possible outcome, according to the data science paper referenced above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GG': 0.23840384261560926,\n",
       " 'GB': 0.24826679089140383,\n",
       " 'BG': 0.24882071317004043,\n",
       " 'BB': 0.2645086533229465}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DK = ProbDist(GG=121801, GB=126840,\n",
    "              BG=127123, BB=135138)\n",
    "DK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Let's write some useful predicates (in lambda syntax):\n",
    "```python\n",
    "def first_girl(outcome):  return outcome[0] == 'G'\n",
    "def first_boy(outcome):   return outcome[0] == 'B'\n",
    "def second_girl(outcome): return outcome[1] == 'G'\n",
    "def second_boy(outcome):  return outcome[1] == 'B'\n",
    "def two_girls(outcome):   return outcome    == 'GG'\n",
    "```\n",
    "Using these predicates, answer the following questions:\n",
    "\n",
    "* **Question 1**: What's the probability for a girl, and is it higher or lower for a ***second*** girl?\n",
    "* **Question 2**: Is the sex of the younger (second) child more likely or less likely to be the same as the first child? And is it more likely to be a boy or a girl?\n",
    "\n",
    "*Hint:* You will leverage the probability of a first girl, the probability of a second girl given that there was a first girl, and the probability of a second girl given that there was a first boy. In other words: `p(first_girl, DK)`, `p(second_girl, such_that(first_girl, DK))`, and `p(second_girl, such_that(first_boy, DK))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def first_girl(outcome):  return outcome[0] == 'G'\n",
    "def first_boy(outcome):   return outcome[0] == 'B'\n",
    "def second_girl(outcome): return outcome[1] == 'G'\n",
    "def second_boy(outcome):  return outcome[1] == 'B'\n",
    "def two_girls(outcome):   return outcome    == 'GG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mp\u001b[49m\u001b[43m(\u001b[49m\u001b[43msecond_girl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuch_that\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfirst_girl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDK\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m,p(second_girl, such_that(first_boy, DK))\n",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object is not callable"
     ]
    }
   ],
   "source": [
    "p(second_girl, such_that(first_girl, DK)),p(second_girl, such_that(first_boy, DK))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above says that the probability of a girl is somewhere between 48% and 49%, but that it is slightly different between the first or second child.\n",
    "\n",
    "Now answer the **question 2** as to whether the sex of the second child is *more likely* or *less likely* to be the same as the first child, by evaluating first:\n",
    "\n",
    "- The probability of a second girl *given that the first child was a girl* (a [conditional probability](https://en.wikipedia.org/wiki/Conditional_probability))\n",
    "- The probability of a second girl *given that the first child was a boy* (a conditional probability)\n",
    "- The probability of a second boy *given that the first child was a boy* (a conditional probability)\n",
    "- The probability of a second boy *given that the first child was a girl* (a conditional probability)\n",
    "\n",
    "The average of the ***first*** two probabilities above represents the probability of a second girl (*irrespective* of any other conditions)! It's a [marginal probability](https://en.wikipedia.org/wiki/Marginal_distribution) in our problem.\n",
    "\n",
    "The average of the ***last*** two probabilities above represents the probability of a second boy, a **marginal probability** in our problem.\n",
    "\n",
    "These are the first two conditional probabilities:\n",
    "```\n",
    "p(second_girl, such_that(first_girl, DK))\n",
    "p(second_girl, such_that(first_boy, DK))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the last two conditional probabilities:\n",
    "```\n",
    "p(second_boy, such_that(first_girl, DK))\n",
    "p(second_boy, such_that(first_boy, DK))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above says that the sex of the second child is more likely to be the same as the first child, by about 1/2 a percentage point.\n",
    "\n",
    "And so, the **marginal probabilities** we are after are:\n",
    "```\n",
    "p_second_girl = (p(second_girl, such_that(first_girl, DK)) + p(second_girl, such_that(first_boy, DK))) / 2\n",
    "p_second_boy = (p(second_boy, such_that(first_girl, DK)) + p(second_boy, such_that(first_boy, DK))) / 2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In conclusion we see that the probability of a girl is somewhere between 48% and 49%, but slightly different between the first or second child, that the sex of the second child is more likely to be the ***same*** as the first child, by about 1/2 a percentage point, and that Danes are more likely to have a ***boy*** as the younger child, rather than a girl, by 2% points. \n",
    "\n",
    "Cooool..! We got all that through *programming*. No math! By spelling out our sets and writing down our logic.\n",
    "\n",
    "<br />\n",
    "<center>\n",
    "<img src=\"ipynb.images/pretty-bunny.gif\" />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# 6. M&Ms and an introduction to Bayes' Theorem\n",
    "<br />\n",
    "<center>\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/en/9/97/M%26M_spokescandies.jpeg\" />\n",
    "</center>\n",
    "\n",
    "[Bayes's theorem](https://en.wikipedia.org/wiki/Bayes%27_theorem) describes the probability of an event $A$, based on prior knowledge of conditions $E$ that might be related to the event:\n",
    "\n",
    "$$P(A \\;|\\; E) = \\frac{P(E \\;|\\; A) \\;*\\; P(A)}{ P(E) }$$\n",
    "\n",
    "Just like the `1 minus` trick for estimating probabilities, you use Bayes' theorem when $P(E \\;|\\; A)$ is easier to compute than $P(A \\;|\\; E)$.\n",
    "\n",
    "For example, if the risk of developing deadly covid19 problems is known to increase with age and medical preconditions. Bayes's theorem allows the risk to an individual of a known age or having a medical precondition to be assessed more accurately than simply assuming that the individual is typical of the population as a whole.\n",
    "\n",
    "Let's study Bayes with another experiment.\n",
    "\n",
    "Here's another urn problem (or \"bag\" problem) [from](http://allendowney.blogspot.com/2011/10/my-favorite-bayess-theorem-problems.html) prolific Python/Probability author [Allen Downey ](http://allendowney.blogspot.com/), which also happens to be a classic interview question:\n",
    "\n",
    "> The blue M&M was introduced in 1995.  Before then, the color mix in a bag of plain M&Ms was (30% Brown, 20% Yellow, 20% Red, 10% Green, 10% Orange, 10% Tan).  Afterward it was (24% Blue , 20% Green, 16% Orange, 14% Yellow, 13% Red, 13% Brown). \n",
    "A friend of mine has two bags of M&Ms, and he picks one M&M from one bag and one from the other, and he tells me that one is from 1994 and one from 1996.  He won't tell me which is which, but he gives me one M&M from each bag.  One is yellow and one is green.  What is the probability that the yellow M&M came from the 1994 bag? Well, the old M&M bags' yellow count was higher, so it must be higher, right? But how to count?\n",
    "\n",
    "To solve this problem, we'll first represent probability distributions for each bag: `bag94` and `bag96`, by using `ProbDist` and passing in dictionaries for each year:\n",
    "```python\n",
    "bag94 = ProbDist(brown=30, yellow=20, red=20, green=10, orange=10, tan=10)\n",
    "bag96 = ProbDist(...)  #fill this in, please\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'brown': 0.3,\n",
       " 'yellow': 0.2,\n",
       " 'red': 0.2,\n",
       " 'green': 0.1,\n",
       " 'orange': 0.1,\n",
       " 'tan': 0.1}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag94"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Next, define `MM` as the *joint* distribution 94-96&mdash;the sample space for picking *one* M&M from *each* bag. The outcome `'yellow green'` means that a yellow M&M was selected from the 1994 bag and a green one from the 1996 bag. We will use a *set comprehension*.\n",
    "\n",
    "Uhhhh... What do we use for sets again? Is it `[`, or `(`, or `{`?\n",
    "\n",
    "To note:\n",
    "* We are using a python *set* because we care about dictionaries, and dictionary keys are unique\n",
    "* You can also think in terms of JSON objects\n",
    "\n",
    "```python\n",
    "def joint(A, B, sep=''):\n",
    "    \"\"\"The joint distribution of two independent probability distributions. \n",
    "    Result is all entries of the form {a+sep+b: P(a)*P(b)}\"\"\"\n",
    "    return ProbDist({a + sep + b: A[a] * B[b]\n",
    "                    for ...\n",
    "                    for ...})\n",
    "\n",
    "MM = joint(bag94, bag96, ' ')\n",
    "MM\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Let's look at the \"One is yellow and one is green\" part:\n",
    "\n",
    "```python\n",
    "def yellow_and_green(outcome): return 'yellow' in outcome and 'green' in outcome\n",
    "\n",
    "such_that(...) # fill this in\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now we can answer the question: given that we got a yellow and a green (but don't know which comes from which bag), what is the probability that the yellow came from the 1994 bag?\n",
    "\n",
    "```python\n",
    "def yellow94(outcome): return ...\n",
    "\n",
    "p(yellow94, such_that(...)) # fill this in\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "So there is a 74% chance that the yellow comes from the 1994 bag. We were *right* about our hunch :-)\n",
    "\n",
    "Answering this question was straightforward: just like all the other probability problems, we simply create a sample space, and use `p` to pick out the probability of the event in question, given what we know about the outcome. This is the 'mechanistic' way of obtaining our answer.\n",
    "\n",
    "# With Math\n",
    "We can *also* solve it using *Bayes' Theorem*, and this is as good as any's introduction to naive Bayes theory: We are asked about the probability of an event (M&M94 --> M&M96) given the evidence (M&M94 is yellow, M&M96 green), which is not immediately available. However the probability of the evidence, given the event is readily available!  \n",
    "\n",
    "Before we see the colors of the M&Ms, there are two hypotheses, `A` and `B`, both with equal probability:\n",
    "\n",
    "    A: first M&M from 94 bag, second from 96 bag\n",
    "    B: first M&M from 96 bag, second from 94 bag\n",
    "    P(A) = P(B) = 0.5\n",
    "    \n",
    "Then we get some evidence:\n",
    "    \n",
    "    E: first M&M yellow, second green\n",
    "    \n",
    "We want to know the probability of hypothesis `A`, given the evidence:\n",
    "    \n",
    "    P(A | E)\n",
    "    \n",
    "That's not easy to calculate (except by enumerating the sample space, which is what we did above). But Bayes Theorem says:\n",
    "    \n",
    "    P(A | E) = P(E | A) * P(A) / P(E)\n",
    "    \n",
    "The quantities on the *right-hand-side* are easier to calculate:\n",
    "    \n",
    "    P(E | A) = 20/100 * 20/100 = 0.04\n",
    "    P(E | B) = 10/100 * 14/100 = 0.014\n",
    "    P(A)     = 0.5\n",
    "    P(B)     = 0.5\n",
    "    P(E)     = P(E | A) * P(A) + P(E | B) * P(B) \n",
    "             = 0.04     * 0.5  + 0.014    * 0.5   =   0.027\n",
    "             \n",
    "Where did the probability of the evidence P(E) formula come from?\n",
    "\n",
    "There are two possibilities of getting the evidence: A and B, a *union* and so we sum their probabilities. The joint probability of the evidence *and* case A is a succession or *intersection*, so it must be a product of their probabilities: P(E|A).P(A). Likewise for the case B: P(E|B).P(B) \n",
    "    \n",
    "And so we can get a final answer:\n",
    "    \n",
    "    P(A | E) = P(E | A) * P(A) / P(E) \n",
    "             = 0.04     * 0.5  / 0.027 \n",
    "             = 0.7407407407\n",
    "             \n",
    "Bayes Theorem allows you to do less calculation at the cost of more algebra; that is a great trade-off if you are working with pencil and paper (like in interview situations). Enumerating the state space allows you to do less algebra at the cost of more calculation; often a good trade-off if you have a computer. But regardless of the approach you use, it is important to understand Bayes theorem and how it works.\n",
    "\n",
    "Bayes' theorem will be our introduction to more advanced statistics, which we'll cover *next* week!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion¶\n",
    "We've built a framework for estimating probabilities that will come in handy when you are asked to build data models. We *started playing* with **Bayes' theorem**, a *pillar* of data science, and we started learning about typical Data Science interview questions, which you should *always* answer in python because you *will* run out of space on the whiteboard if you use squiggly brackets and other languages! \n",
    "\n",
    "Next week we move on to statistical modeling and inference. \n",
    "\n",
    "**Modeling** (one `l` or 2 `l`s? See [here](https://www.grammarly.com/blog/modeling-or-modelling/)) is *harder* when data is scarce and precious and hard to obtain, for example in social sciences and settings where it is difficult to conduct large-scale controlled experiments. \n",
    "\n",
    "With small data it is important to quantify uncertainty and that’s precisely what Bayesian approaches are good at.\n",
    "\n",
    "**Inference** refers to how you learn parameters of your model (Markov Chain Monte Carlo, or MCMC, albeit computationally expensive, is one of the most important methods for statistical inference), which is especially important with Bayesian Machine Learning, where we can actually inquire with Machines why this or that action was undertaken.\n",
    "\n",
    "*Alexa, why did you lower the temperature in the bedroom?* **Because your wife told me that whenever you start snoring, John, colder tempreatures make you bundle up under the cover and you snore less**. \n",
    "\n",
    "<br />\n",
    "<center>\n",
    "    <img src=\"ipynb.images/echo.jpg\" width=200 />\n",
    "</center>\n",
    "\n",
    "Best advice for interviews: Be explicit about what the problem says, have the interviewer verify the working hypotheses, be methodical about defining the sample space, be careful in counting the number of outcomes in the numerator and denominator, and finally use Bayes' theorem (or 1 minus the negation) whenever possible because you will be doing calculations by hand on a whiteboard!\n",
    "\n",
    "<br />\n",
    "<center>\n",
    "    <img src=\"ipynb.images/jobinterview.jpg\" width=400 />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework hint\n",
    "\n",
    "**Conditional probabilities** involve ***prior*** conditions and ***new*** predicates, which is not the same as applying *one* condition on the *entire universe of outcomes*!\n",
    "\n",
    "A conditional probability is usually expressed as A | B (present/future condition A given past condition B). \n",
    "\n",
    "> Example: picking a yellow M&M from the '94 bag given that i've already picked yellow and green M&Ms from each bag. \n",
    "\n",
    "A conditional probability involves a **past event**, and a **present or future condition** (or predicate). So, computing a conditional probability where you specify *all* (past and present/future) conditions (or predicates) in the 1st argument of our p function is *not* possible: You need to first filter your entire universe of outcomes using the 2nd argument of our p function (to specify the past event by limiting the universe of all possible outcomes), and *then* specify the (future, or filter) condition using the 1st argument of our p function.\n",
    "\n",
    "# Reading assignment\n",
    "\n",
    "Please read Chapter 6 of *Mathematics for Machine Learning*, Deisenroth et al."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
